{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle : New York City Taxi Trip Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"taxi.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# purpose of  EDA\n",
    "\n",
    "- Suggest hypotheses about the causes of observed phenomena\n",
    "- Assess assumptions on which statistical inference will be based\n",
    "- Support the selection of appropriate statistical tools and techniques\n",
    "- Provide a basis for further data collection through surveys or experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA methods\n",
    "- Graphical techniques used in EDA are:\n",
    "    - boxplot \n",
    "        - detailed feature (datetime by month, day of week, hours)\n",
    "    - historgram or barplot (distribution) # bin = range of value\n",
    "        - origin feature (pick lat,long, drop lat, long, duration, passenger count, flag)\n",
    "        - detailed feature (datetime by month, day of week, hours)\n",
    "    - scatter plot\n",
    "        - duration vs distance = to check odd data\n",
    "    - Parallel Coordinates vs Colormaps vs Andrews curves charts\n",
    "    - odd ratio????\n",
    "\n",
    "- Quantative methods:\n",
    "    - Trimean == tukey method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Understanding data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.a Data type and unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unit\n",
    "\n",
    "### 1. latitude / longtitude = decimal degree \n",
    "- 111.32mm per 0.000001° / 11.132 m per 0.0001° / 1.1132 km per 0.01° / 111.32 km per 1.0°\n",
    "- 14 demical degree\n",
    "- ex) 40.767937 , -73.982155\n",
    "\n",
    "### 2. datetime = year-month-day: hour-minute-second\n",
    "\n",
    "### 3. vendor_id = 1, 2\n",
    "\n",
    "### 4. passenger_count = 0,,,,9\n",
    "\n",
    "### 4. store_and_fwd_flag = N, Y\n",
    "\n",
    "### 6. duration = second\n",
    "- ex) 455 sec = 7min 35sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data\n",
    "-  1.4M data, 11 columns\n",
    "\n",
    "# test data\n",
    "-  0.6M data, 9 columns (no dropoff_datetime, trip_duration)\n",
    "\n",
    "# sample_submission\n",
    "-  0.6M data, 2 columns (id, trip_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.b Missing Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#none of missing data\n",
    "train2 = train.dropna(how = 'any')\n",
    "test2 = test.dropna(how = 'any')\n",
    "len(train) == len(train2), len(test) == len(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.c Trip duration check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"pickup_datetime\"] =  pd.to_datetime(train[\"pickup_datetime\"])\n",
    "train[\"dropoff_datetime\"] =  pd.to_datetime(train[\"dropoff_datetime\"])\n",
    "sample_duration = train[\"dropoff_datetime\"] - train[\"pickup_datetime\"]\n",
    "sample_duration_sec = sample_duration.dt.total_seconds().astype('int')\n",
    "train['trip_sec'] =  sample_duration_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = train[train[\"trip_duration\"] != train[\"trip_sec\"]]\n",
    "print(len(train_d))\n",
    "\n",
    "if len(train_d) == 0:\n",
    "    train = train.drop(['trip_sec'], axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYC Taxi Trip Duration [Train data]는\n",
    "\n",
    "### 총 1,458,644 Row와 11 Column으로 구성되어 있으며,\n",
    "\n",
    "### Missing Data는 존재하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.c Column information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id : 개별 Taxi에 부여된 고유 id (이건 그냥 쓴거예요...)\n",
    "- verdor_id : Taxi Company id >>>  1, 2로 구성되어 있는걸로 봐서 2개의 회사를 대상\n",
    "- pickup/dropoff datetime : 출발/도착 시간정보 >> 년, 월, 일, 시각 정보가 포함\n",
    "- passenger_count : 승객수 >>> 0~9명까지 존재\n",
    "- pickup/dropoff_longitude & latitude : 출발/도착 지리정보\n",
    "- store_and_fwd_flag : whether the trip data was sent immediately to the vendor (“N”) or held in the memory of the taxi because there was no connection to the server (“Y”)\n",
    "- trip_duration : 탑승시간 >>> 단위는 Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Feature Engineering & Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.a Add columns with detailed informations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- duration per min\n",
    "- datetime per hour\n",
    "- datetime per day of week\n",
    "- datetime per month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# date time convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"dropoff_datetime\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data type convert to datetime from object\n",
    "train[\"pickup_datetime\"] =  pd.to_datetime(train[\"pickup_datetime\"])\n",
    "test[\"pickup_datetime\"] =  pd.to_datetime(test[\"pickup_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#day of week\n",
    "#Monday=0, Sunday=6\n",
    "train[\"pick_month\"] = train[\"pickup_datetime\"].apply(lambda x : x.month)\n",
    "train[\"pick_day\"] = train[\"pickup_datetime\"].apply(lambda x : x.day)\n",
    "train[\"pick_hour\"] = train[\"pickup_datetime\"].apply(lambda x : x.hour)\n",
    "train[\"pick_min\"] = train[\"pickup_datetime\"].apply(lambda x : x.minute)\n",
    "train[\"pick_sec\"] = train[\"pickup_datetime\"].apply(lambda x : x.second)\n",
    "\n",
    "#day of week\n",
    "#Monday=0, Sunday=6\n",
    "test[\"pick_month\"] = test[\"pickup_datetime\"].apply(lambda x : x.month)\n",
    "test[\"pick_day\"] = test[\"pickup_datetime\"].apply(lambda x : x.day)\n",
    "test[\"pick_hour\"] = test[\"pickup_datetime\"].apply(lambda x : x.hour)\n",
    "test[\"pick_min\"] = test[\"pickup_datetime\"].apply(lambda x : x.minute)\n",
    "test[\"pick_sec\"] = test[\"pickup_datetime\"].apply(lambda x : x.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('pickup_datetime', axis=1)\n",
    "test = test.drop('pickup_datetime', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.b Distance between pickup and dropoff location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographic space\n",
    "   - Manhattan distance vs Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean distance\n",
    "- unit = km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York border coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new york city coordinate = (41.145495, −73.994901)\n",
    "city_long_border = (-74.03, -73.75)\n",
    "city_lat_border = (40.63, 40.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximate radius of earth in km\n",
    "# train\n",
    "R = 6371.0\n",
    "\n",
    "dist = []\n",
    "\n",
    "for i in range(len(train)):\n",
    "    lat1 = radians(train.iloc[i,4])\n",
    "    lon1 = radians(train.iloc[i,3])\n",
    "    lat2 = radians(train.iloc[i,6])\n",
    "    lon2 = radians(train.iloc[i,5])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    dist.append(distance)\n",
    "    \n",
    "train['ucli_distance'] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximate radius of earth in km\n",
    "# test\n",
    "R = 6371.0\n",
    "\n",
    "dist = []\n",
    "\n",
    "for i in range(len(test)):\n",
    "    lat1 = radians(test.iloc[i,4])\n",
    "    lon1 = radians(test.iloc[i,3])\n",
    "    lat2 = radians(test.iloc[i,6])\n",
    "    lon2 = radians(test.iloc[i,5])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    dist.append(distance)\n",
    "    \n",
    "test['ucli_distance'] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['man_distance'] = (abs(train.dropoff_longitude - train.pickup_longitude) + abs(train.dropoff_latitude - train.pickup_latitude))\n",
    "test['man_distance'] = (abs(test.dropoff_longitude - test.pickup_longitude) + abs(test.dropoff_latitude - test.pickup_latitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_distance(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n",
    "    '''Calculate the direction of travel in degrees'''\n",
    "    pickup_lat_rads = np.radians(pickup_lat)\n",
    "    pickup_long_rads = np.radians(pickup_long)\n",
    "    dropoff_lat_rads = np.radians(dropoff_lat)\n",
    "    dropoff_long_rads = np.radians(dropoff_long)\n",
    "    long_delta_rads = np.radians(dropoff_long_rads - pickup_long_rads)\n",
    "    \n",
    "    y = np.sin(long_delta_rads) * np.cos(dropoff_lat_rads)\n",
    "    x = (np.cos(pickup_lat_rads) * np.sin(dropoff_lat_rads) - np.sin(pickup_lat_rads) * np.cos(dropoff_lat_rads) * np.cos(long_delta_rads))\n",
    "    \n",
    "    return np.degrees(np.arctan2(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['direction_distance'] = direction_distance(train.pickup_latitude, train.pickup_longitude, train.dropoff_latitude, train.dropoff_longitude)\n",
    "test['direction_distance'] = direction_distance(test.pickup_latitude, test.pickup_longitude, test.dropoff_latitude, test.dropoff_longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.c Outlier Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qualitative analysis\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "### quantitative analysis\n",
    "- Peirce's criterion\n",
    "- Tukey's fences\n",
    "- In anomaly detection\n",
    "- Modified Thompson Tau test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.ucli_distance > 200] = np.nan ##200km 넘는 데이터 제거\n",
    "train.loc[train.trip_duration > 36000] = np.nan ##40000초(약 11시간)가 넘는 데이터 제거\n",
    "train.loc[train.passenger_count == 0] = np.NAN   ### passenger 수가 0인 데이터 제거\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.d.2 Spatial Data Analysis\n",
    "\n",
    "### Types of spatial analysis\n",
    "- FA(factor analysis)\n",
    "    - Euclidean metric = > PCA(principal component analysis)\n",
    "    - Chi-Square distance => Correspondence Analysis (similar to PCA, but better for categrorical data)\n",
    "    - Generalized Mahalanobis distance => Discriminant Analysis \n",
    "\n",
    "- Spatial autocorrelation\n",
    "\n",
    "- Spatial stratified heterogeneity\n",
    "    - geographical detector q-statistic\n",
    "\n",
    "### Spatial dependency or auto-correlation\n",
    "\n",
    "### Scaling\n",
    "\n",
    "### Common errors in spatial analysis\n",
    "- Length\n",
    "- Locational fallacy\n",
    "- Ecological fallacy\n",
    "    - Modifiable areal unit problem\n",
    "        - statistical bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack-up coordinates data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_pick_lat = pd.concat([train['pickup_latitude'], test['pickup_latitude']], axis=0)\n",
    "coord_pick_lon = pd.concat([train['pickup_longitude'], test['pickup_longitude']], axis=0)\n",
    "coord_drop_lat = pd.concat([train['dropoff_latitude'], test['dropoff_latitude']], axis=0)\n",
    "coord_drop_lon = pd.concat([train['dropoff_longitude'], test['dropoff_longitude']], axis=0)\n",
    "\n",
    "coord_lat = pd.concat([coord_pick_lat, coord_drop_lat], axis=1)\n",
    "coord_lon = pd.concat([coord_pick_lon, coord_drop_lon], axis=1)\n",
    "\n",
    "coord_pick = pd.concat([coord_pick_lat, coord_pick_lon], axis=1)\n",
    "coord_drop = pd.concat([coord_drop_lat, coord_drop_lon], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coord_pick_lat), len(coord_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_lat1 = pd.concat([train['pickup_latitude'], train['dropoff_latitude'], test['pickup_latitude'], test['dropoff_latitude']], axis=0)\n",
    "coord_lon1 = pd.concat([train['pickup_longitude'], train['dropoff_longitude'], test['pickup_longitude'], test['dropoff_longitude']], axis=0)\n",
    "coord_all1 = pd.concat([coord_lat1, coord_lon1], axis=1)\n",
    "coord_all1.columns = ['lat', 'lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_all1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coordinates scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=coord_pick_lat, y=coord_pick_lon, fit_reg=False, color=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=coord_drop_lat, y=coord_drop_lon, fit_reg=False, color=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=0).fit(coord_all1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['pca_lat0'] = pca_lat.transform(train[['pickup_latitude']])[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "train['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "train['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "train['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "test['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "test['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "test['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "test['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.d.3 Clustering\n",
    "- DBSCAN\n",
    "- SpectralClustering\n",
    "- Meanshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = GaussianMixture(random_state=0).fit(coord_pick, coord_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansf = MeanShift(n_jobs=-1).fit(coord_pick, coord_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral = SpectralClustering(random_state=0, n_jobs=-1).fit(coord_all1)\n",
    "sepctral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=3, n_jobs=-1).fit(coord_pick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation metric\n",
    "\n",
    "[Root Mean Squared Logarithmic Error](https://www.kaggle.com/wiki/RootMeanSquaredLogarithmicError)\n",
    "\n",
    "$\\epsilon = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\log(p_i + 1) - \\log(a_i+1))^2 }$\n",
    "\n",
    "Where:\n",
    "- ϵ is the RMSLE value (score)\n",
    "\n",
    "- n is the total number of observations in the (public/private) data set,\n",
    "\n",
    "- pi is your prediction of trip duration, and\n",
    "- ai is the actual trip duration for i. \n",
    "- log(x) is the natural logarithm of x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data type manipulation\n",
    "- categorical data convert encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\n",
    "test['store_and_fwd_flag'] = 1 * (test.store_and_fwd_flag.values == 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.get_dummies(train)\n",
    "# test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(labels = [\"trip_duration\",\"trip_sec\", \"pickup_datetime\"], axis=1)\n",
    "Y_train = train[\"trip_duration\"]\n",
    "X_test  = test.drop(labels = [\"pickup_datetime\"], axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_model = sm.OLS(Y_train, X_train).fit()\n",
    "print(OLS_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = OLS_model.predict(X_test)\n",
    "Y_test.head(), len(Y_test)\n",
    "\n",
    "sub = pd.DataFrame(columns= ['id', 'trip_duration'])\n",
    "sub['id'] = sample_submission[\"id\"]\n",
    "sub['trip_duration'] = Y_test\n",
    "sub.to_csv('submission_OLS.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. degree of decimal\n",
    "- 0.000001 = 1.11mm\n",
    "\n",
    "### 2. spatial data analysis\n",
    "- PCA\n",
    "- discriminant analysis\n",
    "\n",
    "### 3. clustering\n",
    "- K means\n",
    "- K nearest neighbor\n",
    "- Expectation Maximization\n",
    "\n",
    "### 4. ensemble methods\n",
    "- aggregation\n",
    "- boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Regression\n",
    "import scipy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "# Decission Tree regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt=DecisionTreeRegressor(max_depth=4).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tree = model_dt.predict(X_test)\n",
    "\n",
    "sub = pd.DataFrame(columns= ['id', 'trip_duration'])\n",
    "sub['id'] = sample_submission[\"id\"]\n",
    "sub['trip_duration'] = y_tree\n",
    "sub.to_csv('submission_tree.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnd_frst=RandomForestRegressor(max_depth=4, n_jobs=4)\n",
    "model_rnd_frst.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_random = model_rnd_frst.predict(X_test)\n",
    "\n",
    "sub = pd.DataFrame(columns= ['id', 'trip_duration'])\n",
    "sub['id'] = sample_submission[\"id\"]\n",
    "sub['trip_duration'] = y_random\n",
    "sub.to_csv('submission_random.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(max_depth=15, n_jobs=4, reg_alpha=0.5, reg_lambda=0.5, random_state=0).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "sub = pd.DataFrame(columns= ['id', 'trip_duration'])\n",
    "sub['id'] = sample_submission[\"id\"]\n",
    "sub['trip_duration'] = y_xgb\n",
    "sub.to_csv('submission_xgb.csv',index=False)\n",
    "#0.42123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
